#!/usr/bin/env python3
"""
Tool ƒë·ªÉ tr√≠ch xu·∫•t t·ªça ƒë·ªô c·ªßa c√°c x√£ ph∆∞·ªùng m·ªõi t·ª´ file CSV
S·ª≠ d·ª•ng OpenStreetMap Nominatim API ƒë·ªÉ l·∫•y t·ªça ƒë·ªô ƒë·ªãa l√Ω
"""

import csv
import requests
import time
import json
import os
from typing import Dict, List, Tuple, Optional
import logging

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CoordinateExtractor:
    def __init__(self, csv_file: str, output_file: str = None):
        """
        Kh·ªüi t·∫°o extractor
        
        Args:
            csv_file: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV g·ªëc
            output_file: ƒê∆∞·ªùng d·∫´n file CSV output (n·∫øu None s·∫Ω ghi ƒë√® file g·ªëc)
        """
        self.csv_file = csv_file
        self.output_file = output_file or csv_file
        self.nominatim_url = "https://nominatim.openstreetmap.org/search"
        self.headers = {
            'User-Agent': 'TPHCM-Ward-Coordinate-Extractor/1.0'
        }
        self.delay = 1.0  # Delay gi·ªØa c√°c request ƒë·ªÉ tr√°nh rate limit
        
    def geocode_location(self, location_name: str, retries: int = 3) -> Optional[Tuple[float, float]]:
        """
        L·∫•y t·ªça ƒë·ªô t·ª´ t√™n ƒë·ªãa danh s·ª≠ d·ª•ng Nominatim API
        
        Args:
            location_name: T√™n ƒë·ªãa danh c·∫ßn t√¨m t·ªça ƒë·ªô
            retries: S·ªë l·∫ßn retry n·∫øu fail
            
        Returns:
            Tuple (lat, lon) ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        # Chu·∫©n h√≥a t√™n ƒë·ªãa danh cho Vi·ªát Nam
        search_query = f"{location_name}, TP.HCM, Vietnam"
        
        params = {
            'q': search_query,
            'format': 'json',
            'limit': 1,
            'countrycodes': 'vn',
            'addressdetails': 1
        }
        
        for attempt in range(retries):
            try:
                logger.info(f"ƒêang t√¨m t·ªça ƒë·ªô cho: {location_name} (l·∫ßn th·ª≠ {attempt + 1})")
                
                response = requests.get(
                    self.nominatim_url, 
                    params=params, 
                    headers=self.headers,
                    timeout=10
                )
                response.raise_for_status()
                
                data = response.json()
                
                if data and len(data) > 0:
                    result = data[0]
                    lat = float(result['lat'])
                    lon = float(result['lon'])
                    logger.info(f"‚úÖ T√¨m th·∫•y t·ªça ƒë·ªô: {lat}, {lon}")
                    return (lat, lon)
                else:
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y t·ªça ƒë·ªô cho: {location_name}")
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"‚ùå L·ªói request (l·∫ßn th·ª≠ {attempt + 1}): {e}")
                if attempt < retries - 1:
                    time.sleep(self.delay * (attempt + 1))
                    
            except (ValueError, KeyError) as e:
                logger.error(f"‚ùå L·ªói parse d·ªØ li·ªáu: {e}")
                break
                
        return None
    
    def read_csv_data(self) -> List[Dict]:
        """
        ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV
        
        Returns:
            List c√°c dictionary ch·ª©a d·ªØ li·ªáu CSV
        """
        data = []
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    data.append(row)
            logger.info(f"‚úÖ ƒê·ªçc th√†nh c√¥ng {len(data)} records t·ª´ {self.csv_file}")
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒë·ªçc file CSV: {e}")
            raise
            
        return data
    
    def write_csv_data(self, data: List[Dict]):
        """
        Ghi d·ªØ li·ªáu v√†o file CSV
        
        Args:
            data: List c√°c dictionary ch·ª©a d·ªØ li·ªáu CSV
        """
        if not data:
            logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ghi")
            return
            
        try:
            fieldnames = list(data[0].keys())
            with open(self.output_file, 'w', encoding='utf-8', newline='') as file:
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
            logger.info(f"‚úÖ Ghi th√†nh c√¥ng {len(data)} records v√†o {self.output_file}")
        except Exception as e:
            logger.error(f"‚ùå L·ªói ghi file CSV: {e}")
            raise
    
    def extract_coordinates(self, dry_run: bool = False) -> Dict[str, int]:
        """
        Tr√≠ch xu·∫•t t·ªça ƒë·ªô cho t·∫•t c·∫£ c√°c x√£ ph∆∞·ªùng m·ªõi
        
        Args:
            dry_run: N·∫øu True, ch·ªâ hi·ªÉn th·ªã k·∫ø ho·∫°ch m√† kh√¥ng th·ª±c hi·ªán
            
        Returns:
            Dict v·ªõi th·ªëng k√™ k·∫øt qu·∫£
        """
        logger.info("üöÄ B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t t·ªça ƒë·ªô...")
        
        # ƒê·ªçc d·ªØ li·ªáu CSV
        data = self.read_csv_data()
        
        # Th√™m c·ªôt t·ªça ƒë·ªô n·∫øu ch∆∞a c√≥
        if 'Latitude' not in data[0]:
            for row in data:
                row['Latitude'] = ''
                row['Longitude'] = ''
        
        stats = {
            'total': len(data),
            'processed': 0,
            'found': 0,
            'not_found': 0,
            'errors': 0
        }
        
        if dry_run:
            logger.info("üîç DRY RUN - Ch·ªâ hi·ªÉn th·ªã k·∫ø ho·∫°ch:")
            for i, row in enumerate(data[:5]):  # Ch·ªâ hi·ªÉn th·ªã 5 records ƒë·∫ßu
                ward_name = row['Xa_Phuong_Moi_TPHCM']
                logger.info(f"  {i+1}. S·∫Ω t√¨m t·ªça ƒë·ªô cho: {ward_name}")
            logger.info(f"... v√† {len(data)-5} records kh√°c")
            return stats
        
        # X·ª≠ l√Ω t·ª´ng record
        for i, row in enumerate(data):
            ward_name = row['Xa_Phuong_Moi_TPHCM']
            
            # B·ªè qua n·∫øu ƒë√£ c√≥ t·ªça ƒë·ªô
            if row['Latitude'] and row['Longitude']:
                logger.info(f"‚è≠Ô∏è B·ªè qua {ward_name} (ƒë√£ c√≥ t·ªça ƒë·ªô)")
                stats['processed'] += 1
                continue
            
            logger.info(f"üìç ƒêang x·ª≠ l√Ω {i+1}/{len(data)}: {ward_name}")
            
            # L·∫•y t·ªça ƒë·ªô
            coordinates = self.geocode_location(ward_name)
            
            if coordinates:
                lat, lon = coordinates
                row['Latitude'] = str(lat)
                row['Longitude'] = str(lon)
                stats['found'] += 1
                logger.info(f"‚úÖ Th√†nh c√¥ng: {ward_name} -> {lat}, {lon}")
            else:
                stats['not_found'] += 1
                logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {ward_name}")
            
            stats['processed'] += 1
            
            # Delay ƒë·ªÉ tr√°nh rate limit
            if i < len(data) - 1:  # Kh√¥ng delay ·ªü record cu·ªëi
                time.sleep(self.delay)
        
        # Ghi d·ªØ li·ªáu ƒë√£ c·∫≠p nh·∫≠t
        self.write_csv_data(data)
        
        # In th·ªëng k√™
        logger.info("üìä TH·ªêNG K√ä K·∫æT QU·∫¢:")
        logger.info(f"  T·ªïng s·ªë records: {stats['total']}")
        logger.info(f"  ƒê√£ x·ª≠ l√Ω: {stats['processed']}")
        logger.info(f"  T√¨m th·∫•y t·ªça ƒë·ªô: {stats['found']}")
        logger.info(f"  Kh√¥ng t√¨m th·∫•y: {stats['not_found']}")
        logger.info(f"  L·ªói: {stats['errors']}")
        
        return stats

def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y tool t·ª´ command line
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='Tr√≠ch xu·∫•t t·ªça ƒë·ªô c√°c x√£ ph∆∞·ªùng TPHCM')
    parser.add_argument('--input', '-i', default='Phuong_TPHCM_Formatted.CSV',
                       help='File CSV input (default: Phuong_TPHCM_Formatted.CSV)')
    parser.add_argument('--output', '-o', 
                       help='File CSV output (n·∫øu kh√¥ng ch·ªâ ƒë·ªãnh s·∫Ω ghi ƒë√® file input)')
    parser.add_argument('--dry-run', action='store_true',
                       help='Ch·ªâ hi·ªÉn th·ªã k·∫ø ho·∫°ch, kh√¥ng th·ª±c hi·ªán')
    parser.add_argument('--delay', type=float, default=1.0,
                       help='Delay gi·ªØa c√°c request (gi√¢y, default: 1.0)')
    
    args = parser.parse_args()
    
    # Ki·ªÉm tra file input t·ªìn t·∫°i
    if not os.path.exists(args.input):
        logger.error(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {args.input}")
        return 1
    
    # Kh·ªüi t·∫°o extractor
    extractor = CoordinateExtractor(args.input, args.output)
    extractor.delay = args.delay
    
    try:
        # Ch·∫°y tr√≠ch xu·∫•t t·ªça ƒë·ªô
        stats = extractor.extract_coordinates(dry_run=args.dry_run)
        
        if not args.dry_run:
            logger.info("üéâ Ho√†n th√†nh tr√≠ch xu·∫•t t·ªça ƒë·ªô!")
        else:
            logger.info("üîç Dry run ho√†n th√†nh!")
            
        return 0
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è D·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        return 1
    except Exception as e:
        logger.error(f"‚ùå L·ªói kh√¥ng mong mu·ªën: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
